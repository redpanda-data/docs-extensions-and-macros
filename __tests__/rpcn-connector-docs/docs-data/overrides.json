{
  "metrics": [
    {
      "name": "prometheus",
      "summary": "Host endpoints (`/metrics` and `/stats`) for Prometheus scraping.",
      "config": {
        "children": [
          {
            "name": "use_histogram_timing",
            "description": "Whether to export timing metrics as a histogram, if `false` a summary is used instead. When exporting histogram timings the delta values are converted from nanoseconds into seconds in order to better fit within bucket definitions."
          },
          {
            "name": "histogram_buckets",
            "description": "Timing metrics histogram buckets (in seconds). If left empty defaults to DefBuckets. Applicable when `use_histogram_timing` is set to `true`."
          },
          {
            "name": "summary_quantiles_objectives",
            "description": "A list of timing metrics summary buckets (as quantiles). Applicable when `use_histogram_timing` is set to `false`."
          },
          {
            "name": "add_process_metrics",
            "description": "Whether to export process metrics such as CPU and memory usage in addition to Redpanda Connect metrics."
          },
          {
            "name": "add_go_metrics",
            "description": "Whether to export Go runtime metrics such as GC pauses in addition to Redpanda Connect metrics."
          },
          {
            "name": "push_url",
            "description": "An optional Push Gateway URL to push metrics to."
          },
          {
            "name": "push_interval",
            "description": "The period of time between each push when sending metrics to a Push Gateway."
          },
          {
            "name": "push_job_name",
            "description": "An identifier for push jobs."
          },
          {
            "name": "push_basic_auth",
            "description": "The Basic Authentication credentials."
          },
          {
            "name": "file_output_path",
            "description": "An optional file path to write all prometheus metrics on service shutdown."
          }
        ]
      }
    }
  ],
  "tracers": [
    {
      "name": "jaeger",
      "summary": "Send tracing events to a Jaeger agent or collector.",
      "config": {
        "children": [
          {
            "name": "agent_address",
            "description": "The address of a Jaeger agent to send tracing events to."
          },
          {
            "name": "collector_url",
            "description": "The URL of a Jaeger collector to send tracing events to. If set, this will override `agent_address`."
          },
          {
            "name": "sampler_type",
            "description": "The sampler type to use."
          },
          {
            "name": "sampler_param",
            "description": "A parameter to use for sampling. This field is unused for some sampling types."
          },
          {
            "name": "tags",
            "description": "A map of tags to add to tracing spans."
          },
          {
            "name": "flush_interval",
            "description": "The period of time between each flush of tracing spans."
          }
        ]
      }
    },
    {
      "name": "open_telemetry_collector",
      "summary": "Send tracing events to an Open Telemetry collector.",
      "config": {
        "children": [
          {
            "name": "http",
            "description": "A list of http collectors."
          },
          {
            "name": "http[].address",
            "description": "The endpoint of a collector to send tracing events to."
          },
          {
            "name": "http[].secure",
            "description": "Connect to the collector over HTTPS"
          },
          {
            "name": "grpc",
            "description": "A list of grpc collectors."
          },
          {
            "name": "grpc[].address",
            "description": "The endpoint of a collector to send tracing events to."
          },
          {
            "name": "grpc[].secure",
            "description": "Connect to the collector with client transport security"
          },
          {
            "name": "tags",
            "description": "A map of tags to add to all tracing spans."
          },
          {
            "name": "sampling",
            "description": "Settings for trace sampling. Sampling is recommended for high-volume production workloads."
          },
          {
            "name": "sampling.enabled",
            "description": "Whether to enable sampling."
          },
          {
            "name": "sampling.ratio",
            "description": "Sets the ratio of traces to sample."
          }
        ]
      }
    }
  ],
  "rate_limits": [
    {
      "name": "local",
      "summary": "The local rate limit is a simple X every Y type rate limit that can be shared across any number of components within the pipeline but does not support distributed rate limits across multiple instances.",
      "config": {
        "children": [
          {
            "name": "count",
            "description": "The maximum number of requests to allow for a given period of time."
          },
          {
            "name": "interval",
            "description": "The time window to limit requests by."
          }
        ]
      }
    },
    {
      "name": "redis",
      "summary": "A rate limit implementation using Redis. It works by using a simple token bucket algorithm to limit the number of requests to a given count within a given time period.",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path."
          },
          {
            "name": "kind",
            "description": "Specifies a simple, cluster-aware, or failover-aware redis client."
          },
          {
            "name": "master",
            "description": "Name of the redis master when `kind` is `failover`"
          },
          {
            "name": "count",
            "description": "The maximum number of messages to allow for a given period of time."
          },
          {
            "name": "interval",
            "description": "The time window to limit requests by."
          },
          {
            "name": "key",
            "description": "The key to use for the rate limit."
          }
        ]
      }
    }
  ],
  "buffers": [
    {
      "name": "memory",
      "summary": "The memory buffer stores consumed messages in memory and acknowledges them at the input level. During shutdown, Redpanda Connect attempts to flush all remaining messages before exiting cleanly.",
      "config": {
        "children": [
          {
            "name": "limit",
            "description": "Optional limit of messages to hold in the buffer. When this limit is reached back pressure will be applied upstream until the buffer is below the limit again. If set to zero then no limit is applied."
          },
          {
            "name": "byte_size",
            "description": "Optional maximum size in bytes to allocate for buffered messages. When this limit is reached back pressure will be applied upstream until the buffer is below the limit again. If set to zero then no limit is applied."
          },
          {
            "name": "batch_policy",
            "description": "Optional batch policy configuration to enable batching messages through the buffer. This can improve throughput at the cost of latency.",
            "children": [
              {
                "name": "count",
                "description": "The number of messages at which the batch should be flushed."
              },
              {
                "name": "byte_size",
                "description": "An approximate size in bytes at which the batch should be flushed."
              },
              {
                "name": "period",
                "description": "A period in which an incomplete batch should be flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "A list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. This allows you to aggregate and archive the batch however you see fit. Please note that all resulting messages are flushed as a single batch, therefore splitting the batch into smaller batches using these processors is a no-op."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "sqlite",
      "summary": "The SQLite buffer stores messages in an SQLite database and acknowledges them at the input level.",
      "config": {
        "children": [
          {
            "name": "path",
            "description": "The file path to use for the SQLite database. If the directory does not exist it will be created."
          },
          {
            "name": "pre_processors",
            "description": "An optional list of processors to apply to messages before they are stored within the buffer. These processors are useful for compressing, archiving or otherwise reducing the data in size before it's stored on disk."
          },
          {
            "name": "post_processors",
            "description": "An optional list of processors to apply to messages after they are consumed from the buffer. These processors are useful for undoing any compression, archiving, etc that may have been done by your `pre_processors`."
          }
        ]
      }
    },
    {
      "name": "none",
      "summary": "Do not buffer messages. This is the default and most resilient configuration.",
      "config": {
        "children": []
      }
    },
    {
      "name": "system_window",
      "config": {
        "children": [
          {
            "name": "window_size",
            "description": "The size of windows to create. Each window represents a fixed period of time in which messages will be grouped together. This determines the granularity of your time-based aggregation."
          },
          {
            "name": "timestamp_mapping",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang mapping] applied to each message during ingestion that provides the timestamp to use for allocating it a window. By default the function `now()` is used in order to generate a fresh timestamp at the time of ingestion (the processing time), whereas this mapping can instead extract a timestamp from the message itself (the event time). The timestamp value assigned to `root` must either be a numerical unix time in seconds (with up to nanosecond precision via decimals), or a string in ISO 8601 format. If the mapping fails or provides an invalid result the message will be dropped (with logging to describe the problem)."
          },
          {
            "name": "slide",
            "description": "An optional duration string describing by how much time the beginning of each window should be offset from the beginning of the previous, and therefore creates sliding windows instead of tumbling. When specified this duration must be smaller than the `size` of the window."
          },
          {
            "name": "offset",
            "description": "An optional duration string to offset the beginning of each window by, otherwise they are aligned to the zeroth minute and zeroth hour on the UTC clock. The offset cannot be a larger or equal measure to the window size or the slide."
          },
          {
            "name": "allowed_lateness",
            "description": "An optional duration string describing the length of time to wait after a window has ended before flushing it, allowing late arrivals to be included. Since this windowing buffer uses the system clock an allowed lateness can improve the matching of messages when using event time."
          },
          {
            "name": "alignment_timezone",
            "description": "An optional timezone identifier used to align windows. By default, windows are aligned to UTC time. Use this to align windows to a local timezone."
          },
          {
            "name": "append_limited_to_highest",
            "description": "Whether to add a new message exclusively to its highest potential window. If set to true, the message will only be added to the most recent eligible window rather than all eligible windows."
          },
          {
            "name": "output_dropped_messages",
            "description": "Whether messages that are dropped due to being too late should be delivered with an added metadata field 'window_dropped' with a value of 'true'."
          }
        ]
      }
    }
  ],
  "caches": [
    {
      "name": "memory",
      "config": {
        "children": [
          {
            "name": "default_ttl",
            "description": "The default TTL of each item. After this period an item will be eligible for removal during the next compaction."
          },
          {
            "name": "compaction_interval",
            "description": "The period of time to wait before each compaction, at which point expired items are removed. This field can be set to an empty string in order to disable compactions/expiry entirely."
          },
          {
            "name": "init_values",
            "description": "A table of key/value pairs that should be present in the cache on initialization. This can be used to create static lookup tables."
          },
          {
            "name": "shards",
            "description": "A number of logical shards to spread keys across, increasing the shards can have a performance benefit when processing a large number of keys."
          }
        ]
      }
    },
    {
      "name": "redis",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL of the target Redis server. Database is optional and is supplied as the URL path."
          },
          {
            "name": "prefix",
            "description": "An optional string to prefix item keys with in order to prevent collisions with similar services."
          },
          {
            "name": "expiration",
            "description": "An optional period after which cache items should expire. Set to zero or empty string to set no expiration. Redis handles the expiration automatically without requiring separate compaction."
          },
          {
            "name": "retries",
            "description": "Determine time intervals and cut offs for retry attempts.",
            "children": [
              {
                "name": "initial_interval",
                "description": "The initial period to wait between retry attempts."
              },
              {
                "name": "max_interval",
                "description": "The maximum period to wait between retry attempts."
              },
              {
                "name": "max_elapsed_time",
                "description": "The maximum overall period of time to spend on retry attempts before the request is aborted."
              }
            ]
          }
        ]
      }
    },
    {
      "name": "lru",
      "config": {
        "children": [
          {
            "name": "cap",
            "description": "The cache maximum capacity (number of entries)"
          },
          {
            "name": "init_values",
            "description": "A table of key/value pairs that should be present in the cache on initialization. This can be used to create static lookup tables."
          },
          {
            "name": "algorithm",
            "description": "the lru cache implementation"
          },
          {
            "name": "two_queues_recent_ratio",
            "description": "is the ratio of the two_queues cache dedicated to recently added entries that have only been accessed once."
          },
          {
            "name": "two_queues_ghost_ratio",
            "description": "is the default ratio of ghost entries kept to track entries recently evicted on two_queues cache."
          },
          {
            "name": "optimistic",
            "description": "If true, we do not lock on read/write events. The lru package is thread-safe, however the ADD operation is not atomic."
          }
        ]
      }
    },
    {
      "name": "ttlru",
      "config": {
        "children": [
          {
            "name": "cap",
            "description": "The cache maximum capacity (number of entries)"
          },
          {
            "name": "default_ttl",
            "description": "The cache ttl of each element"
          },
          {
            "name": "ttl",
            "description": "Deprecated. Please use `default_ttl` field"
          },
          {
            "name": "init_values",
            "description": "A table of key/value pairs that should be present in the cache on initialization. This can be used to create static lookup tables."
          },
          {
            "name": "optimistic",
            "description": "If true, we do not lock on read/write events. The ttlru package is thread-safe, however the ADD operation is not atomic."
          }
        ]
      }
    },
    {
      "name": "aws_dynamodb",
      "config": {
        "children": [
          {
            "name": "table",
            "description": "The table to store items in."
          },
          {
            "name": "hash_key",
            "description": "The key of the table column to store item keys within."
          },
          {
            "name": "data_key",
            "description": "The key of the table column to store item values within."
          },
          {
            "name": "prefix",
            "description": "An optional string prefix to add to all item keys. This allows multiple caches to share the same DynamoDB table under different namespaces."
          },
          {
            "name": "ttl",
            "description": "An optional period after which items should expire. Requires the table to have TTL enabled."
          },
          {
            "name": "ttl_key",
            "description": "The column key to place the TTL value within."
          },
          {
            "name": "consistent_read",
            "description": "Whether to use strongly consistent reads on Get commands."
          }
        ]
      }
    },
    {
      "name": "aws_s3",
      "config": {
        "children": [
          {
            "name": "bucket",
            "description": "The S3 bucket to store items in."
          },
          {
            "name": "prefix",
            "description": "An optional string prefix to add to all object keys. This allows multiple caches to share the same bucket under different paths."
          },
          {
            "name": "content_type",
            "description": "The content type to set for each item."
          },
          {
            "name": "region",
            "description": "The AWS region to target."
          }
        ]
      }
    },
    {
      "name": "file",
      "config": {
        "children": [
          {
            "name": "directory",
            "description": "The directory within which to store items."
          },
          {
            "name": "file_mode",
            "description": "The permissions mode to use for created files, expressed as an octal integer. For example, 0666 allows reading and writing for all users."
          },
          {
            "name": "dir_mode",
            "description": "The permissions mode to use for automatically created directories, expressed as an octal integer. This allows you to control directory access permissions."
          }
        ]
      }
    }
  ],
  "inputs": [
    {
      "name": "kafka",
      "config": {
        "children": [
          {
            "name": "addresses",
            "description": "A list of broker addresses to connect to. If an item of the list contains commas it will be expanded into multiple addresses."
          },
          {
            "name": "topics",
            "description": "A list of topics to subscribe to. Multiple comma separated topics can be listed in a single element. Partitions are automatically distributed across consumers of a topic. Alternatively, it's possible to specify explicit partitions to consume from with a colon after the topic name, e.g. `foo:0` would consume the partition 0 of the topic foo. This syntax supports ranges, e.g. `foo:0-10` would consume partitions 0 through to 10 inclusive."
          },
          {
            "name": "consumer_group",
            "description": "An identifier for the consumer group of the connection. This field can be explicitly made empty in order to disable stored offsets for the consumed topic partitions."
          },
          {
            "name": "checkpoint_limit",
            "description": "The maximum number of messages of the same topic and partition that can be processed at a given time. Increasing this limit enables parallel processing and batching at the output level to work on individual partitions. Any given offset will not be committed unless all messages under that offset are delivered in order to preserve at least once delivery guarantees."
          },
          {
            "name": "instance_id",
            "description": "When you specify a `consumer_group`, assign a unique value to `instance_id` to help brokers identify each input after restarts and prevent unnecessary rebalances."
          },
          {
            "name": "batching",
            "description": "Allows you to configure batching of message sets, which can significantly improve throughput at the cost of increased latency."
          },
          {
            "name": "tls",
            "description": "Custom TLS settings can be used to override system defaults."
          }
        ]
      }
    },
    {
      "name": "http_client",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL to connect to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "verb",
            "description": "The HTTP verb to use when making the request. Common options include GET, POST, PUT, and DELETE."
          },
          {
            "name": "headers",
            "description": "A map of headers to add to the request. Both keys and values support interpolation functions for dynamic headers based on message content."
          },
          {
            "name": "rate_limit",
            "description": "An optional rate limit resource to restrict request rates. Useful for APIs with rate limits to prevent throttling or IP bans."
          },
          {
            "name": "timeout",
            "description": "The maximum duration to wait for a request to complete before abandoning it. Prevents hanging on slow or unresponsive endpoints."
          },
          {
            "name": "retry_period",
            "description": "The base period to wait between retry attempts. Uses exponential backoff by default, doubling the wait time after each failed attempt."
          },
          {
            "name": "max_retry_backoff",
            "description": "The maximum period to wait between retry attempts. Prevents excessive delays between retries when using exponential backoff."
          },
          {
            "name": "retry_limit",
            "description": "The maximum number of retry attempts to make before giving up on a request. Set to -1 for unlimited retries."
          },
          {
            "name": "drop_on",
            "description": "A list of HTTP status codes whereby the request should be considered failed but not retried. Useful for client errors that won't be resolved by retrying."
          }
        ]
      }
    },
    {
      "name": "http_server",
      "config": {
        "children": [
          {
            "name": "address",
            "description": "An alternative address to host from. If left empty the service wide address is used."
          },
          {
            "name": "path",
            "description": "The endpoint path to listen for POST requests."
          },
          {
            "name": "ws_path",
            "description": "The endpoint path to create websocket connections from."
          },
          {
            "name": "timeout",
            "description": "Timeout for requests. If a consumed messages takes longer than this to be delivered the connection is closed, but the message may still be delivered."
          },
          {
            "name": "cors",
            "description": "Adds Cross-Origin Resource Sharing headers. Only valid with a custom `address`."
          },
          {
            "name": "sync_response",
            "description": "Customize messages returned via xref:guides:sync_responses.adoc[synchronous responses].",
            "children": [
              {
                "name": "status",
                "description": "Specify the status code to return with synchronous responses. This is a string value, which allows you to customize it based on resulting payloads and their metadata. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              },
              {
                "name": "headers",
                "description": "Specify headers to return with synchronous responses. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
              },
              {
                "name": "metadata_headers",
                "description": "Specify criteria for which metadata values are added to the response as headers.",
                "children": [
                  {
                    "name": "include_prefixes",
                    "description": "Provide a list of explicit metadata key prefixes to match against."
                  },
                  {
                    "name": "include_patterns",
                    "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against."
                  }
                ]
              }
            ]
          }
        ]
      }
    }
  ],
  "processors": [
    {
      "name": "mapping",
      "summary": "Executes a xref:guides:bloblang/about.adoc[Bloblang] mapping on messages, creating a new document that replaces (or filters) the original message.",
      "config": {
        "children": [
          {
            "name": "mapping",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang] mapping to apply to messages. If the mapping fails or is empty then the message continues unchanged. If your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"<path>\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from."
          }
        ]
      }
    },
    {
      "name": "mutation",
      "summary": "Executes a xref:guides:bloblang/about.adoc[Bloblang] mapping and directly transforms the contents of messages, mutating (or deleting) them.",
      "config": {
        "children": [
          {
            "name": "mutation",
            "description": "A xref:guides:bloblang/about.adoc[Bloblang] mapping to apply to messages. If the mapping fails or is empty then the message continues unchanged. If your mapping is large and you'd prefer for it to live in a separate file then you can execute a mapping directly from a file with the expression `from \"<path>\"`, where the path must be absolute, or relative from the location that Redpanda Connect is executed from."
          }
        ]
      }
    },
    {
      "name": "archive",
      "summary": "Archives all the messages of a batch into a single message according to the selected archive format.",
      "config": {
        "children": [
          {
            "name": "format",
            "description": "The archiving format to apply."
          },
          {
            "name": "path",
            "description": "The path to set for each message in the archive (when applicable). This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    },
    {
      "name": "sql",
      "summary": "Runs an arbitrary SQL query against a database and (optionally) returns the result as an array of objects, one for each row returned.",
      "config": {
        "children": [
          {
            "name": "driver",
            "description": "A database driver to use."
          },
          {
            "name": "data_source_name",
            "description": "Data source name."
          },
          {
            "name": "query",
            "description": "The query to execute. The style of placeholder to use depends on the driver, some drivers require question marks (`?`) whereas others expect incrementing dollar signs (`$1`, `$2`, and so on) or colons (`:1`, `:2` and so on)."
          },
          {
            "name": "unsafe_dynamic_query",
            "description": "Whether to enable xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions] in the query. Great care should be made to ensure your queries are defended against injection attacks."
          },
          {
            "name": "args_mapping",
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] which should evaluate to an array of values matching in size to the number of placeholder arguments in the field `query`."
          },
          {
            "name": "result_codec",
            "description": "Result codec."
          }
        ]
      }
    },
    {
      "name": "log",
      "summary": "Prints a log event for each message. Messages always remain unchanged. The log message can be set using function interpolations described in xref:configuration:interpolation.adoc#bloblang-queries[Bloblang queries].",
      "config": {
        "children": [
          {
            "name": "level",
            "description": "The log level to use."
          },
          {
            "name": "fields_mapping",
            "description": "An optional xref:guides:bloblang/about.adoc[Bloblang mapping] that can be used to specify extra fields to add to the log. If log fields are also added with the `fields` field then those values will override matching keys from this mapping."
          },
          {
            "name": "message",
            "description": "The message to print. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          }
        ]
      }
    }
  ],
  "outputs": [
    {
      "name": "kafka",
      "summary": "The `kafka` output writes a batch of messages to Kafka brokers and waits for acknowledgement before propagating any acknowledgements back to the input.",
      "config": {
        "children": [
          {
            "name": "addresses",
            "description": "A list of broker addresses to connect to. If an item of the list contains commas it will be expanded into multiple addresses."
          },
          {
            "name": "topic",
            "description": "The topic to publish messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "key",
            "description": "The key to publish messages with. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "partitioner",
            "description": "The partitioning algorithm to use."
          },
          {
            "name": "compression",
            "description": "The compression algorithm to use."
          },
          {
            "name": "static_headers",
            "description": "An optional map of static headers that should be added to messages in addition to metadata."
          },
          {
            "name": "metadata",
            "description": "Specify criteria for which metadata values are sent with messages as headers.",
            "children": [
              {
                "name": "exclude_prefixes",
                "description": "Provide a list of explicit metadata key prefixes to be excluded when adding metadata to sent messages."
              }
            ]
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput."
          },
          {
            "name": "retry_as_batch",
            "description": "When enabled forces an entire batch of messages to be retried if any individual message fails on a send, otherwise only the individual messages that failed are retried. Disabling this helps to reduce message duplicates during intermittent errors, but also makes it impossible to guarantee strict ordering of messages."
          },
          {
            "name": "batching",
            "description": "Allows you to configure batching of message sets, which can significantly improve throughput at the cost of increased latency."
          }
        ]
      }
    },
    {
      "name": "http_client",
      "summary": "Sends messages to a HTTP server.",
      "config": {
        "children": [
          {
            "name": "url",
            "description": "The URL to connect to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "verb",
            "description": "A verb to connect with."
          },
          {
            "name": "headers",
            "description": "A map of headers to add to the request. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions]."
          },
          {
            "name": "metadata",
            "description": "Specify matching rules that determine which metadata keys to add to the HTTP request as headers (optional).",
            "children": [
              {
                "name": "include_prefixes",
                "description": "Provide a list of explicit metadata key prefixes to match against."
              },
              {
                "name": "include_patterns",
                "description": "Provide a list of explicit metadata key regular expression (re2) patterns to match against."
              }
            ]
          },
          {
            "name": "timeout",
            "description": "A static timeout to apply to requests."
          },
          {
            "name": "retry_period",
            "description": "The initial period to wait between failed requests before retrying."
          },
          {
            "name": "max_retry_backoff",
            "description": "The maximum period to wait between failed requests."
          },
          {
            "name": "retries",
            "description": "The maximum number of retry attempts to make."
          },
          {
            "name": "backoff_on",
            "description": "A list of status codes that indicate a request failure and trigger retries with an increasing backoff period between attempts."
          },
          {
            "name": "drop_on",
            "description": "A list of status codes that indicate a request failure where the input should not attempt retries. This helps avoid unnecessary retries for requests that are unlikely to succeed."
          },
          {
            "name": "max_in_flight",
            "description": "The maximum number of messages to have in flight at a given time. Increase this to improve throughput."
          },
          {
            "name": "batching",
            "description": "Allows you to configure a xref:configuration:batching.adoc[batching policy].",
            "children": [
              {
                "name": "count",
                "description": "The number of messages after which the batch is flushed. Set to `0` to disable count-based batching."
              },
              {
                "name": "byte_size",
                "description": "The amount of bytes at which the batch is flushed. Set to `0` to disable size-based batching."
              },
              {
                "name": "period",
                "description": "The period after which an incomplete batch is flushed regardless of its size."
              },
              {
                "name": "check",
                "description": "A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch."
              },
              {
                "name": "processors",
                "description": "For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches."
              }
            ]
          }
        ]
      }
    }
  ],
  "scanners": [
    {
      "name": "csv",
      "summary": "Consume comma-separated values row by row, including support for custom delimiters.",
      "config": {
        "children": [
          {
            "name": "custom_delimiter",
            "description": "Use a provided custom delimiter instead of the default comma."
          },
          {
            "name": "parse_header_row",
            "description": "Whether to reference the first row as a header row. If set to true the output structure for messages will be an object where field keys are determined by the header row. Otherwise, each message will consist of an array of values from the corresponding CSV row."
          },
          {
            "name": "lazy_quotes",
            "description": "If set to `true`, a quote may appear in an unquoted field and a non-doubled quote may appear in a quoted field."
          },
          {
            "name": "continue_on_error",
            "description": "If a row fails to parse due to any error emit an empty message marked with the error and then continue consuming subsequent rows when possible. This can sometimes be useful in situations where input data contains individual rows which are malformed. However, when a row encounters a parsing error it is impossible to guarantee that following rows are valid, as this indicates that the input data is unreliable and could potentially emit misaligned rows."
          }
        ]
      }
    },
    {
      "name": "json_documents",
      "summary": "Consumes a stream of one or more JSON documents.",
      "config": {
        "children": []
      }
    },
    {
      "name": "lines",
      "summary": "Split an input stream into a message per line of data.",
      "config": {
        "children": [
          {
            "name": "custom_delimiter",
            "description": "Use a provided custom delimiter for detecting the end of a line rather than a single line break."
          },
          {
            "name": "max_buffer_size",
            "description": "Set the maximum buffer size for storing line data, this limits the maximum size that a line can be without causing an error."
          },
          {
            "name": "omit_empty",
            "description": "Omit empty lines."
          }
        ]
      }
    },
    {
      "name": "chunker",
      "summary": "Split an input stream into chunks of a given number of bytes.",
      "config": {
        "children": [
          {
            "name": "size",
            "description": "The size of each chunk in bytes."
          }
        ]
      }
    },
    {
      "name": "avro",
      "summary": "Consume a stream of Avro OCF datum.",
      "config": {
        "children": [
          {
            "name": "raw_json",
            "description": "Whether messages should be decoded into normal JSON (JSON that meets the expectations of regular internet JSON) rather than Avro JSON. If `true`, the schema returned from the subject is decoded as standard JSON instead of as Avro JSON."
          }
        ]
      }
    }
  ],
  "aws_cloudwatch": [
    {
      "name": "aws_cloudwatch",
      "summary": "Send metrics to AWS CloudWatch using the PutMetricData endpoint.",
      "config": {
        "children": [
          {
            "name": "namespace",
            "description": "The namespace used to distinguish metrics from other services."
          },
          {
            "name": "flush_period",
            "description": "The period of time between PutMetricData requests."
          },
          {
            "name": "region",
            "description": "The AWS region to target."
          },
          {
            "name": "endpoint",
            "description": "Allows you to specify a custom endpoint for the AWS API."
          },
          {
            "name": "credentials",
            "description": "Optional manual configuration of AWS credentials to use."
          },
          {
            "name": "credentials.profile",
            "description": "A profile from `~/.aws/credentials` to use."
          },
          {
            "name": "credentials.id",
            "description": "The ID of credentials to use."
          },
          {
            "name": "credentials.secret",
            "description": "The secret for the credentials being used."
          },
          {
            "name": "credentials.token",
            "description": "The token for the credentials being used, required when using short term credentials."
          },
          {
            "name": "credentials.from_ec2_role",
            "description": "Use the credentials of a host EC2 machine configured to assume an IAM role associated with the instance."
          },
          {
            "name": "credentials.role",
            "description": "A role ARN to assume."
          },
          {
            "name": "credentials.role_external_id",
            "description": "An external ID to provide when assuming a role."
          }
        ]
      }
    }
  ]
}

