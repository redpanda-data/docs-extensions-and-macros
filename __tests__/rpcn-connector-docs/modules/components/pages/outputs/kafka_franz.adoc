= kafka_franz
// tag::single-source[]
:type: output
:status: beta
:categories: ["Services"]

// © 2024 Redpanda Data Inc.


component_type_dropdown::[]


The `kafka_franz` output writes a batch of messages to Kafka brokers and waits for acknowledgement before propagating any acknowledgments back to the input. This output often outperforms the traditional `kafka` output, as well as providing more useful logs and error messages.

This output uses the https://github.com/twmb/franz-go[Franz Kafka client library^].

ifndef::env-cloud[]
Introduced in version 3.61.0.
endif::[]

[tabs]
======
Common::
+
--

```yml
# Common configuration fields, showing default values
output:
  label: ""
  kafka_franz:
    seed_brokers: [] # No default (required)
    topic: "" # No default (required)
    key: "" # No default (optional)
    partition: ${! meta("partition") } # No default (optional)
    metadata:
      include_prefixes: []
      include_patterns: []
    max_in_flight: 10
    batching:
      count: 0
      byte_size: 0
      period: ""
      check: ""
```

--
Advanced::
+
--

```yml
# All configuration fields, showing default values
output:
  label: ""
  kafka_franz:
    seed_brokers: [] # No default (required)
    topic: "" # No default (required)
    key: "" # No default (optional)
    partitioner: "" # No default (optional)
    partition: ${! meta("partition") } # No default (optional)
    client_id: benthos
    idempotent_write: true
    metadata:
      include_prefixes: []
      include_patterns: []
    max_in_flight: 10
    timeout: 10s
    batching:
      count: 0
      byte_size: 0
      period: ""
      check: ""
      processors: [] # No default (optional)
    max_message_bytes: 1MiB
    broker_write_max_bytes: 100MiB
    compression: "" # No default (optional)
    tls:
      enabled: false
      skip_cert_verify: false
      enable_renegotiation: false
      root_cas: ""
      root_cas_file: ""
      client_certs: []
    sasl: [] # No default (optional)
    metadata_max_age: 5m
    timestamp_ms: ${! timestamp_unix_milli() } # No default (optional)
```

--
======

== Fields

=== `seed_brokers`

A list of broker addresses to connect to in order. Use commas to separate multiple addresses in a single list item.

*Type*: `array`


```yml
# Examples

seed_brokers:
  - localhost:9092

seed_brokers:
  - foo:9092
  - bar:9092

seed_brokers:
  - foo:9092,bar:9092
```

=== `topic`

A topic to write messages to. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

=== `key`

An optional key to populate for each message. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

=== `partitioner`

Override the default murmur2 hashing partitioner.

*Type*: `string`

|===
| Option | Summary

| `least_backup`
| Choose the partition with the fewest buffered records. Partitions are selected per batch.
| `manual`
| Manually select a partition for each message. You must also specify a value for the `partition` field.
| `murmur2_hash`
| Kafka's default hash algorithm that uses a 32-bit murmur2 hash of the key to compute the partition for the record.
| `round_robin`
| Use round-robin messages through all available partitions. This algorithm has lower throughput and causes higher CPU load on brokers, but is useful if you want to ensure an even distribution of records to partitions.

|===

=== `partition`

Set a partition for each message (optional). This field is only relevant when the `partitioner` is set to `manual`.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

You must provide an interpolation string that is a valid integer.

*Type*: `string`


```yml
# Examples

partition: ${! meta("partition") }
```

=== `client_id`

An identifier for the client connection.

*Type*: `string`

*Default*: `benthos`

=== `idempotent_write`

Enables the idempotent write producer option. This requires the `IDEMPOTENT_WRITE` permission on `CLUSTER`. Disable this option if the `IDEMPOTENT_WRITE` permission is unavailable.

*Type*: `bool`

*Default*: `true`

=== `metadata`

Specify which (if any) metadata values are added to messages as headers.

*Type*: `object`


=== `metadata.include_prefixes`

Provide a list of explicit metadata key prefixes to match against.


*Type*: `array`

*Default*: `[]`

```yml
# Examples

include_prefixes:
  - foo_
  - bar_

include_prefixes:
  - kafka_

include_prefixes:
  - content-
```

=== `metadata.include_patterns`

Provide a list of explicit metadata key regular expression (re2) patterns to match against.


*Type*: `array`

*Default*: `[]`

```yml
# Examples

include_patterns:
  - .*

include_patterns:
  - _timestamp_unix$
```

=== `max_in_flight`

The maximum number of batches to send in parallel at any given time.

*Type*: `int`

*Default*: `10`

=== `timeout`

The maximum period of time to wait for message sends before abandoning the request and retrying.

*Type*: `string`

*Default*: `10s`

=== `batching`

Allows you to configure a xref:configuration:batching.adoc[batching policy].


*Type*: `object`


```yml
# Examples

batching:
  byte_size: 5000
  count: 0
  period: 1s

batching:
  count: 10
  period: 1s

batching:
  check: this.contains("END BATCH")
  count: 0
  period: 1m
```

=== `batching.count`

The number of messages after which the batch is flushed. Set to `0` to disable count-based batching.

*Type*: `int`

*Default*: `0`

=== `batching.byte_size`

The number of bytes at which the batch is flushed. Set to `0` to disable size-based batching.

*Type*: `int`

*Default*: `0`

=== `batching.period`

The period after which an incomplete batch is flushed regardless of its size.


*Type*: `string`

*Default*: `""`

```yml
# Examples

period: 1s

period: 1m

period: 500ms
```

=== `batching.check`

A xref:guides:bloblang/about.adoc[Bloblang query] that should return a boolean value indicating whether a message should end a batch.

*Type*: `string`

*Default*: `""`

```yml
# Examples

check: this.type == "end_of_transaction"
```

=== `batching.processors`

For aggregating and archiving message batches, you can add a list of xref:components:processors/about.adoc[processors] to apply to a batch as it is flushed. All resulting messages are flushed as a single batch even when you configure processors to split the batch into smaller batches.


*Type*: `array`


```yml
# Examples

processors:
  - archive:
      format: concatenate

processors:
  - archive:
      format: lines

processors:
  - archive:
      format: json_array
```

=== `max_message_bytes`

The maximum space (in bytes) that an individual message may use. Messages larger than this value are rejected. This field corresponds to Kafka's `max.message.bytes`.

*Type*: `string`

*Default*: `1MiB`

```yml
# Examples

max_message_bytes: 100MiB

max_message_bytes: 50MiB
```

=== `broker_write_max_bytes`

The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafka’s `socket.request.max.bytes`.

*Type*: `string`

*Default*: `100MiB`

```yml
# Examples

broker_write_max_bytes: 128MiB

broker_write_max_bytes: 50MiB
```

=== `compression`

Set an explicit compression type (optional). The default preference is to use `snappy` when the broker supports it. Otherwise, use `none`.

*Type*: `string`

Options:
`lz4`
, `snappy`
, `gzip`
, `none`
, `zstd`

=== `tls`

Override system defaults with custom TLS settings.

*Type*: `object`

=== `tls.enabled`

Whether custom TLS settings are enabled.

*Type*: `bool`

*Default*: `false`

=== `tls.skip_cert_verify`

Whether to skip server-side certificate verification.


*Type*: `bool`

*Default*: `false`

=== `tls.enable_renegotiation`

Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.


*Type*: `bool`

*Default*: `false`

ifndef::env-cloud[]
Requires version 3.45.0 or newer
endif::[]

=== `tls.root_cas`

Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate.

include::components:partial$secret_warning.adoc[]


*Type*: `string`

*Default*: `""`

```yml
# Examples

root_cas: |-
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----
```

=== `tls.root_cas_file`

Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate.

*Type*: `string`

*Default*: `""`

```yml
# Examples

root_cas_file: ./root_cas.pem
```

=== `tls.client_certs`

A list of client certificates to use. For each certificate specify values for either the `cert` and `key` fields, or `cert_file` and `key_file` fields.

*Type*: `array`

*Default*: `[]`

```yml
# Examples

client_certs:
  - cert: foo
    key: bar

client_certs:
  - cert_file: ./example.pem
    key_file: ./example.key
```

=== `tls.client_certs[].cert`

The plain text certificate to use.


*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].key`

The plain text certificate key to use.

include::components:partial$secret_warning.adoc[]

*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].cert_file`

The path to the certificate to use.

*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].key_file`

The path of a certificate key to use.


*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].password`

The plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.

WARNING: The `pbeWithMD5AndDES-CBC` algorithm does not authenticate ciphertext, and is vulnerable to padding oracle attacks which may allow an attacker to recover the plain text password.

include::components:partial$secret_warning.adoc[]

*Type*: `string`

*Default*: `""`

```yml
# Examples

password: foo

password: ${KEY_PASSWORD}
```

=== `sasl`

Specify one or more methods or mechanisms of SASL authentication, which are attempted in order. If the broker supports the first SASL mechanism, all connections use it. If the first mechanism fails, the client picks the first supported mechanism. If the broker does not support any client mechanisms, all connections fail.

*Type*: `array`


```yml
# Examples

sasl:
  - mechanism: SCRAM-SHA-512
    password: bar
    username: foo
```

=== `sasl[].mechanism`

The SASL mechanism to use.


*Type*: `string`


|===
| Option | Summary

| `AWS_MSK_IAM`
| AWS IAM-based authentication as specified by the 'aws-msk-iam-auth' Java library.
| `OAUTHBEARER`
| OAuth bearer-based authentication.
| `PLAIN`
| Plain text authentication.
| `SCRAM-SHA-256`
| SCRAM-based authentication as specified in RFC5802.
| `SCRAM-SHA-512`
| SCRAM-based authentication as specified in RFC5802.
| `none`
| Disable SASL authentication

|===

=== `sasl[].username`

A username to provide for `PLAIN` or `SCRAM-*` authentication.


*Type*: `string`

*Default*: `""`

=== `sasl[].password`

A password to provide for `PLAIN` or `SCRAM-*` authentication.

include::components:partial$secret_warning.adoc[]


*Type*: `string`

*Default*: `""`

=== `sasl[].token`

The token to use for a single session's `OAUTHBEARER` authentication.


*Type*: `string`

*Default*: `""`

=== `sasl[].extensions`

Key/value pairs to add to `OAUTHBEARER` authentication requests.


*Type*: `object`


=== `sasl[].aws`

AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.


*Type*: `object`


=== `sasl[].aws.region`

The AWS region to target.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.endpoint`

Specify a custom endpoint for the AWS API.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials`

Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[].

*Type*: `object`

=== `sasl[].aws.credentials.profile`

The profile from `~/.aws/credentials` to use.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.id`

The ID of the AWS credentials to use.

*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.secret`

The secret for the AWS credentials in use.

include::components:partial$secret_warning.adoc[]

*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.token`

The token for the AWS credentials in use. This is a required value for short-term credentials.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.from_ec2_role`

Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].


*Type*: `bool`

*Default*: `false`

ifndef::env-cloud[]
Requires version 4.2.0 or newer
endif::[]

=== `sasl[].aws.credentials.role`

The role ARN to assume.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.role_external_id`

An external ID to use when assuming a role.


*Type*: `string`

*Default*: `""`

=== `metadata_max_age`

The maximum period of time after which metadata is refreshed.

*Type*: `string`

*Default*: `5m`


=== `timestamp_ms`

Set a timestamp (in milliseconds) for each message (optional). When left empty, the current timestamp is used.
This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].


*Type*: `string`

```yml
# Examples

timestamp_ms: ${! timestamp_unix_milli() }

timestamp_ms: ${! metadata("kafka_timestamp_ms") }
```

// end::single-source[]