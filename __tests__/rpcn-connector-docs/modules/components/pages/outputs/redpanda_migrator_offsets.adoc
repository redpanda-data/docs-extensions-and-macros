= redpanda_migrator_offsets
:page-aliases: components:outputs/kafka_migrator_offsets.adoc
// tag::single-source[]
:type: output
:page-beta: true
:categories: ["Services"]


// Â© 2024 Redpanda Data Inc.


component_type_dropdown::[]

Migrates offset data to a Redpanda cluster. To achieve this, pair the `redpanda_migrator_offsets` output with a matching xref:components:outputs/redpanda_migrator_bundle.adoc[`redpanda_migrator_bundle` input].

Alternatively, use the `redpanda_migrator_bundle` xref:components:inputs/redpanda_migrator_bundle.adoc[input] and xref:components:outputs/redpanda_migrator_bundle.adoc[output] to complete the migration of topics, messages, and schemas to a Redpanda cluster.

This output uses the https://github.com/twmb/franz-go[Franz Kafka client library^].


ifndef::env-cloud[]
Introduced in version 4.37.0.
endif::[]

[tabs]
======
Common::
+
--

```yml
# Common configuration fields, showing default values
output:
  label: ""
  redpanda_migrator_offsets:
    seed_brokers: [] # No default (required)
    offset_topic: ${! @kafka_offset_topic }
    offset_group: ${! @kafka_offset_group }
    offset_partition: ${! @kafka_offset_partition }
    offset_commit_timestamp: ${! @kafka_offset_commit_timestamp }
    offset_metadata: ${! @kafka_offset_metadata }
    is_high_watermark: ${! @kafka_is_high_watermark }
```

--
Advanced::
+
--

```yml
# All configuration fields, showing default values
output:
  label: ""
  redpanda_migrator_offsets:
    seed_brokers: [] # No default (required)
    client_id: benthos
    tls:
      enabled: false
      skip_cert_verify: false
      enable_renegotiation: false
      root_cas: "" # Optional
      root_cas_file: "" # Optional
      client_certs: [] # Optional
    sasl: [] # No default (optional)
    metadata_max_age: 5m
    offset_topic: ${! @kafka_offset_topic }
    offset_group: ${! @kafka_offset_group }
    offset_partition: ${! @kafka_offset_partition }
    offset_commit_timestamp: ${! @kafka_offset_commit_timestamp }
    offset_metadata: ${! @kafka_offset_metadata }
    is_high_watermark: ${! @kafka_is_high_watermark }
    timeout: 10s
    max_message_bytes: 1MiB
    broker_write_max_bytes: 100MiB
    max_retries: 0
    backoff:
      initial_interval: 1s
      max_interval: 5s
      max_elapsed_time: 30s
```

--
======

== Fields

=== `seed_brokers`

A list of broker addresses to connect to. Use commas to separate multiple addresses in a single list item.

*Type*: `array`


```yml
# Examples

seed_brokers:
  - localhost:9092

seed_brokers:
  - foo:9092
  - bar:9092

seed_brokers:
  - foo:9092,bar:9092
```

=== `client_id`

An identifier for the client connection.

*Type*: `string`

*Default*: `benthos`


=== `tls`

Override system defaults with custom TLS settings.


*Type*: `object`

=== `tls.enabled`

Whether custom TLS settings are enabled.

*Type*: `bool`

*Default*: `false`

=== `tls.skip_cert_verify`

Whether to skip server-side certificate verification.

*Type*: `bool`

*Default*: `false`

=== `tls.enable_renegotiation`

Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.


*Type*: `bool`

*Default*: `false`

ifndef::env-cloud[]
Requires version 3.45.0 or newer
endif::[]

=== `tls.root_cas`

Specify a certificate authority to use (optional). This is a string that represents a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate.

include::components:partial$secret_warning.adoc[]

*Type*: `string`

*Default*: `""`

```yml
# Examples

root_cas: |-
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----
```

=== `tls.root_cas_file`

Specify the path to a root certificate authority file (optional). This is a file, often with a `.pem` extension, which contains a certificate chain from the parent-trusted root certificate, through possible intermediate signing certificates, to the host certificate.


*Type*: `string`

*Default*: `""`

```yml
# Examples

root_cas_file: ./root_cas.pem
```

=== `tls.client_certs`

A list of client certificates to use. For each certificate, specify values for either the `cert` and `key`, or `cert_file` and `key_file` fields.


*Type*: `array`

*Default*: `[]`

```yml
# Examples

client_certs:
  - cert: foo
    key: bar

client_certs:
  - cert_file: ./example.pem
    key_file: ./example.key
```

=== `tls.client_certs[].cert`

A plain text certificate to use.


*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].key`

A plain text certificate key to use.

include::components:partial$secret_warning.adoc[]


*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].cert_file`

The path of a certificate to use.


*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].key_file`

The path of a certificate key to use.


*Type*: `string`

*Default*: `""`

=== `tls.client_certs[].password`

A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format.

Because the obsolete `pbeWithMD5AndDES-CBC` algorithm does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.

include::components:partial$secret_warning.adoc[]


*Type*: `string`

*Default*: `""`

```yml
# Examples

password: foo

password: ${KEY_PASSWORD}
```

=== `sasl`

Specify one or more methods of SASL authentication, which are attempted in order. If the broker supports the first mechanism, all connections use that mechanism. If the first mechanism fails, the client picks the first supported mechanism. Connections fail if the broker does not support any client mechanisms.


*Type*: `array`


```yml
# Examples

sasl:
  - mechanism: SCRAM-SHA-512
    password: bar
    username: foo
```

=== `sasl[].mechanism`

The SASL mechanism to use.


*Type*: `string`


|===
| Option | Summary

| `AWS_MSK_IAM`
| AWS IAM-based authentication as specified by the `aws-msk-iam-auth` Java library.
| `OAUTHBEARER`
| OAuth bearer-based authentication.
| `PLAIN`
| Plain text authentication.
| `SCRAM-SHA-256`
| SCRAM-based authentication as specified in RFC 5802.
| `SCRAM-SHA-512`
| SCRAM-based authentication as specified in RFC 5802.
| `none`
| Disable SASL authentication.

|===

=== `sasl[].username`

A username to provide for `PLAIN` or `SCRAM-*` authentication.


*Type*: `string`

*Default*: `""`

=== `sasl[].password`

A password to provide for `PLAIN` or `SCRAM-*` authentication.

include::components:partial$secret_warning.adoc[]


*Type*: `string`

*Default*: `""`

=== `sasl[].token`

The token to use for a single session's `OAUTHBEARER` authentication.


*Type*: `string`

*Default*: `""`

=== `sasl[].extensions`

Key/value pairs to add to `OAUTHBEARER` authentication requests.


*Type*: `object`


=== `sasl[].aws`

Contains AWS specific fields for when the `mechanism` is set to `AWS_MSK_IAM`.


*Type*: `object`


=== `sasl[].aws.region`

The AWS region to target.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.endpoint`

Specify a custom endpoint for the AWS API.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials`

Manually configure the AWS credentials to use (optional). For more information, see the xref:guides:cloud/aws.adoc[Amazon Web Services guide].

*Type*: `object`

=== `sasl[].aws.credentials.profile`

A profile from `~/.aws/credentials` to use.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.id`

The ID of credentials to use.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.secret`

The secret for the credentials being used.

include::components:partial$secret_warning.adoc[]


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.token`

The token for the credentials being used, required when using short-term credentials.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.from_ec2_role`

Use the credentials of a host EC2 machine configured to assume https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html[an IAM role associated with the instance^].


*Type*: `bool`

*Default*: `false`

ifndef::env-cloud[]
Requires version 4.2.0 or newer
endif::[]

=== `sasl[].aws.credentials.role`

A role ARN to assume.


*Type*: `string`

*Default*: `""`

=== `sasl[].aws.credentials.role_external_id`

An external ID to provide when assuming a role.

*Type*: `string`

*Default*: `""`


=== `metadata_max_age`

The maximum period of time after which metadata is refreshed.

*Type*: `string`

*Default*: `5m`

=== `offset_topic`

The name of the Kafka offset topic to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `${! @kafka_offset_topic }`

=== `offset_group`

The name of the Kafka offset consumer group to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `${! @kafka_offset_group }`

=== `offset_partition`

The Kafka offset partition ID to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `${! @kafka_offset_partition }`

=== `offset_commit_timestamp`

The Kafka offset commit timestamp to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `${! @kafka_offset_commit_timestamp }`

=== `offset_metadata`

The Kafka offset metadata value to process. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `${! @kafka_offset_metadata }`

=== `is_high_watermark`

Indicates whether the processed message is the high watermark, which is the offset of the last fully replicated message in the Kafka topic partition. This field supports xref:configuration:interpolation.adoc#bloblang-queries[interpolation functions].

*Type*: `string`

*Default*: `${! @kafka_is_high_watermark }`


=== `timeout`

The maximum period of time to wait for message sends before abandoning the request and retrying it.


*Type*: `string`

*Default*: `10s`

=== `max_message_bytes`

The maximum number of bytes that an individual message may use. Messages larger than this value are rejected. This field corresponds to Kafka's `max.message.bytes`.


*Type*: `string`

*Default*: `1MiB`

```yml
# Examples

max_message_bytes: 100MiB

max_message_bytes: 50MiB
```

=== `broker_write_max_bytes`

The maximum number of bytes this output can write to a broker connection in a single write. This field corresponds to Kafkaâs `socket.request.max.bytes`.


*Type*: `string`

*Default*: `100MB`

```yml
# Examples

broker_write_max_bytes: 128MiB

broker_write_max_bytes: 50MiB
```

=== `max_retries`

The maximum number of retries before giving up on the request. If set to `0`, there is no discrete limit.


*Type*: `int`

*Default*: `0`


=== `backoff`

Control the time intervals between retry attempts.

*Type*: `object`


=== `backoff.initial_interval`

The initial amount of time to wait between retry attempts. This value increases for each failed attempt up to the `backoff.max_interval` value.

*Type*: `string`

*Default*: `1s`


=== `backoff.max_interval`

The maximum amount of time to wait between retry attempts.

*Type*: `string`

*Default*: `5s`


=== `backoff.max_elapsed_time`

The maximum amount of time to wait before retry attempts are abandoned. If set to `0`, there is no waiting period.

*Type*: `string`

*Default*: `30s`

// end::single-source[]
